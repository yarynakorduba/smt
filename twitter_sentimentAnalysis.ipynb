{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:08:23.527682800Z",
     "start_time": "2023-06-02T08:08:23.508678Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pyarrow import feather\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T07:28:53.996320100Z",
     "start_time": "2023-06-02T07:28:10.120567700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def write_to_feather(df, name):\n",
    "    root_dir = os.path.dirname(os.path.abspath('twitter_sentimentAnalysis.ipynb'))\n",
    "    path = os.path.join(root_dir, 'twitter_res/' + name)\n",
    "    feather.write_feather(df, path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:06:23.635735100Z",
     "start_time": "2023-06-02T08:06:23.618739600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_twitter_old = pd.read_feather(\"twitter_res/twitter_old.ftr\")\n",
    "df_twitter_new = pd.read_feather(\"twitter_res/twitter_new.ftr\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:06:29.520909600Z",
     "start_time": "2023-06-02T08:06:26.313437300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " climate change interesting hustle global warming planet stopped warming 15 yes suv boom \n"
     ]
    }
   ],
   "source": [
    "print(df_twitter_old['tweet'][0]);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:06:30.258673600Z",
     "start_time": "2023-06-02T08:06:30.234682Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [0.01343372 0.56145763 0.42510867]\n",
      "3000: [0.11462115 0.8682781  0.01710073]\n",
      "6000: [0.03462958 0.88376236 0.08160809]\n",
      "9000: [0.83620507 0.15550041 0.00829458]\n",
      "12000: [0.01532613 0.8692461  0.11542763]\n",
      "15000: [0.02356858 0.7689509  0.20748055]\n",
      "18000: [0.03332511 0.87329644 0.09337848]\n",
      "21000: [0.06901434 0.69873685 0.23224889]\n",
      "24000: [0.5294029  0.38407466 0.08652245]\n",
      "27000: [0.18921433 0.773444   0.03734165]\n",
      "30000: [0.0109002  0.9530916  0.03600808]\n",
      "33000: [0.3270773  0.5920179  0.08090478]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                   tweet    tweet_ts  \\\n0       climate change interesting hustle global warm...  31-10-2016   \n1       watch #beforetheflood right here,  travels wo...  31-10-2016   \n2      fabulous! leonardo #dicaprio's film #climate c...  31-10-2016   \n3       watched amazing documentary leonardodicaprio ...  31-10-2016   \n4       pranita biswasi, lutheran odisha, gives testi...  31-10-2016   \n...                                                  ...         ...   \n43934  #awareness walls aren$q$t answer people fleein...  26-10-2016   \n43935          americans scared clowns climate change.    26-10-2016   \n43939  respective parties prevent climate change glob...  26-10-2016   \n43941   still can$q$t believe gif taehyung saved huma...  26-10-2016   \n43942    wealthy + fossil fuel industry know climate ...  26-10-2016   \n\n                    hashtags                          sentimentScore  \n0                         []   [0.013433724, 0.56145763, 0.42510867]  \n1          [#beforetheflood]     [0.019552002, 0.795175, 0.18527298]  \n2      [#dicaprio, #climate]  [0.0022631218, 0.01210344, 0.98563343]  \n3                         []  [0.0034224496, 0.031758707, 0.9648187]  \n4                         []    [0.021988245, 0.9171695, 0.06084218]  \n...                      ...                                     ...  \n43934           [#awareness]    [0.62899506, 0.3573929, 0.013611956]  \n43935                     []    [0.7736483, 0.20565642, 0.020695252]  \n43939           [#zpndebate]    [0.1894237, 0.77215046, 0.038425878]  \n43941                     []   [0.028441388, 0.19685273, 0.77470595]  \n43942                     []   [0.22790794, 0.66404897, 0.108043104]  \n\n[33966 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>tweet_ts</th>\n      <th>hashtags</th>\n      <th>sentimentScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>climate change interesting hustle global warm...</td>\n      <td>31-10-2016</td>\n      <td>[]</td>\n      <td>[0.013433724, 0.56145763, 0.42510867]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>watch #beforetheflood right here,  travels wo...</td>\n      <td>31-10-2016</td>\n      <td>[#beforetheflood]</td>\n      <td>[0.019552002, 0.795175, 0.18527298]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fabulous! leonardo #dicaprio's film #climate c...</td>\n      <td>31-10-2016</td>\n      <td>[#dicaprio, #climate]</td>\n      <td>[0.0022631218, 0.01210344, 0.98563343]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>watched amazing documentary leonardodicaprio ...</td>\n      <td>31-10-2016</td>\n      <td>[]</td>\n      <td>[0.0034224496, 0.031758707, 0.9648187]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pranita biswasi, lutheran odisha, gives testi...</td>\n      <td>31-10-2016</td>\n      <td>[]</td>\n      <td>[0.021988245, 0.9171695, 0.06084218]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43934</th>\n      <td>#awareness walls aren$q$t answer people fleein...</td>\n      <td>26-10-2016</td>\n      <td>[#awareness]</td>\n      <td>[0.62899506, 0.3573929, 0.013611956]</td>\n    </tr>\n    <tr>\n      <th>43935</th>\n      <td>americans scared clowns climate change.</td>\n      <td>26-10-2016</td>\n      <td>[]</td>\n      <td>[0.7736483, 0.20565642, 0.020695252]</td>\n    </tr>\n    <tr>\n      <th>43939</th>\n      <td>respective parties prevent climate change glob...</td>\n      <td>26-10-2016</td>\n      <td>[#zpndebate]</td>\n      <td>[0.1894237, 0.77215046, 0.038425878]</td>\n    </tr>\n    <tr>\n      <th>43941</th>\n      <td>still can$q$t believe gif taehyung saved huma...</td>\n      <td>26-10-2016</td>\n      <td>[]</td>\n      <td>[0.028441388, 0.19685273, 0.77470595]</td>\n    </tr>\n    <tr>\n      <th>43942</th>\n      <td>wealthy + fossil fuel industry know climate ...</td>\n      <td>26-10-2016</td>\n      <td>[]</td>\n      <td>[0.22790794, 0.66404897, 0.108043104]</td>\n    </tr>\n  </tbody>\n</table>\n<p>33966 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "allScores = [[] for i in range(len(df_twitter_old['tweet']))]\n",
    "\n",
    "for tweet in df_twitter_old['tweet']:\n",
    "    encoded_input = tokenizer(tweet, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores) #scores = [negative, neutral, positive] -> Are always in this order\n",
    "    # check if data is modeld correctly\n",
    "    if counter % 3000 == 0:\n",
    "        print(f'{counter}: {scores}')\n",
    "    allScores[counter] = scores\n",
    "    counter += 1\n",
    "\n",
    "df_twitter_old['sentimentScore'] = allScores\n",
    "df_twitter_old"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:08:44.520584400Z",
     "start_time": "2023-06-02T08:08:44.200467600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#save the data\n",
    "write_to_feather(df_twitter_old, 'twitter_old_analysis.ftr')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:08:47.861918700Z",
     "start_time": "2023-06-02T08:08:47.790376100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#df_twitter_test = pd.read_feather(\"twitter_res/twitter_old_analysis.ftr\");\n",
    "#df_twitter_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:09:40.487423Z",
     "start_time": "2023-06-02T08:09:40.467428300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0.013433724"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter_old['sentimentScore'][0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:01:44.429317700Z",
     "start_time": "2023-06-02T08:01:44.410323800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [0.7790241  0.21138299 0.00959283]\n",
      "10000: [0.00229184 0.16949917 0.82820904]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "allScores = [[] for i in range(len(df_twitter_new['tweet']))]\n",
    "\n",
    "for tweet in df_twitter_new['tweet']:\n",
    "    encoded_input = tokenizer(tweet, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores) #scores = [negative, neutral, positive]\n",
    "    #print(f'{counter}: {scores}')\n",
    "    if counter % 10000 == 0:\n",
    "        print(f'{counter}: {scores}')\n",
    "    allScores[counter] = scores\n",
    "    counter += 1\n",
    "\n",
    "df_twitter_new['sentimentScore'] = allScores\n",
    "df_twitter_new"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T08:10:34.533428Z",
     "start_time": "2023-06-02T08:10:33.861572300Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#save the data\n",
    "write_to_feather(df_twitter_new, 'twitter_new_analysis.ftr')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}